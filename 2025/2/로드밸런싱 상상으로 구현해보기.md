어느정도 구조와 개념을 파악한 상태에서, 나라면 여기서 어떤 문제를 어떻게 해결할 것인지? 어떤 점들을 고려해야되는지에 대해서 한 번 혼자서 생각을 해보는 순간들이 종종 있다.

아마 근래에 웹 애플리케이션이 동작하는 전체적인 구조에 대해서 공부하고 있는 것 + 멘토님이 던져주신 화두(Nextjs가 SSR인데 이 SSR로 인해서 서버에 가해지는 부담은 어떻게 측정할 것인지?와 같은..)로 인해서 이런 방식으로 사고하게 되는 것 같음.

# 로드 밸런싱을 어떻게 구현할 수 있을까?

백엔드 서버로 요청이 몰릴 때, 하나의 서버가 감당하지 못해서 터지는 상황을 방지하기 위해서 어떤 해결책을 적용할 수 있을까?

쉽게 말해서, 서버가 안터지게 하려면 뭐 어떻게 해야되나?

그러면 서버는 왜 터지나? -> 터지는 이유를 파악하고 그에 대한 해결책을 구상해야 한다.

트래픽이 몰릴 때 터진다.(터진다가 셧다운일 수도 있고, 무한정 대기하는 상황일수도 있고)

결국 컴퓨터가 한 번에 처리할 수 있는 처리량보다 많은 요청이 들어왔을 때, 문제가 생긴다는 것.

이런 문제를 해결하려면? 가장 최선책은 서버 용량이 엄청 커서 모든 처리를 그때그때 해주는 것이겠지만 결국 돈....돈문제가 있어서 이건 안된다.

그러면 제한된 범위 내의 처리 능력 안에서 어떻게 서버가 터지는 것을 방지하나?

터지는 이유가 트래픽이 몰려서 라고 했으니까, 트래픽이 몰리지 않게 하면 되지 않을까? 하는 생각이 자연스럽게 든다.

요청이 하나의 서버에 몰리지 않게 하려면? 여러 서버에 부하를 분산시켜서, 지금 케파가 남는 서버에서 요청을 처리할 수 있는 구조로 만들면 되겠지.

이게 로드 밸런싱의 근간이 되는 아이디어인듯. 그리고 로드밸런싱이라는 아이디어 덕분에 단일 서버에 의존하는 구조에서 벗어나서 확장성을 가진 구조로 앱을 설계할 수 있게 되었다고 함.

로드 밸런싱을 하려면 뭐가 필요할까?

**로드 밸런싱 준비물(내 생각)**

- 서버 여러 대
- 서버 여러 대에 연결되어 있는 분산 장치(물리적인 장치인지 소프트웨어적으로 처리하는지? 아니지 뭔가 근데 물리적인 장치가 있어야할 것 같음 왜냐하면 IP 주소가 있어야할 것 같은데...)
  - 사용자들의 요청을 middleware느낌으로 받아서, 상태 좋은 서버로 전달하는 역할. (근데 궁금한게 그러면 요청에 대한 서버의 응답도 load balancer를 거쳐가야하나?)
- 각 서버의 가용성 상태를 확인할 수 있는 메커니즘.(헬스체크라고 하는 듯)
- 엣지케이스들에 대한 처리방식 결정
  - 가용성이 다 괜찮은 상태에서 어떤 서버로 요청을 전송할 것인지?(전략이 뭔지? 하나의 서버의 가용성을 우선 최대로 맞추고 그 다음 서버로 옮긴다? 아니면 모든 서버의 가용성이 비슷한 수준으로 유지되도록 맞춘다?)
    - 이를 위해서도 알고리즘이 사용된다고 함.(정적 로드밸런싱, 동적 로드밸런싱에 따라서 사용되는 알고리즘들이 존재함.)
  - 모든 서버가 포화상태인 경우, 어떻게 처리할 것인지?
- 로드밸런서 자체에 부하가 많이 걸리는 문제는 없는지에 대한 대책
  - [Do load balancers flood](https://stackoverflow.com/questions/36771929/do-load-balancers-flood)

클라이언트 컴퓨터가 서버로 요청 전송 -> 로드밸런서에서 요청을 받아서 연결된 서버들 상태 확인 -> 상태 괜찮은 서버로 전송 -> 서버에서 처리 이런 flow로 처리되겠지?

로드밸런서 역할을 수행하는 물리 장치는 어떻게 서버로 전송된 요청을 대신 받아서 처리할 수 있는지? 미들웨어 같은 역할을 어떻게 수행하는거야?

- 네트워크를 통해서 요청을 보낼 때 원하는 위치로 전송하려면 주소가 필요하잖아. 로드밸런서가 물리적인 장치라면 이 장치로 요청이 전송될 수 있도록 뭔가 주소를 노출시켜줘야 한다. 즉 부하 분산의 대상인 서비스에 대한 요청이 최종 목적지인 서버가 아니라 로드밸런서로 전송될 수 있게 해야한다.

# (부록) 서버가 '터지는' 이유

서버가 터진다는 표현은 많이 들어봤는데, 정확히 어떻게 됐을 때 터진다고 하는건지, 트래픽이 몰렸을 때 어떻게 터지는건지 몰라서 궁금해서 한 번 찾아봄.

이해의 시작점은 하드웨어가 되어야 함. -> 그렇지 어쨌든 서버도 물리적인 컴퓨터고, 하드웨어가 로직을 수행하면서 작업을 처리하니까.

CPU + SSD + RAM 등으로 구성되어 있음

CPU는 데이터 처리를 하고, 데이터 처리를 위해서 필요한 프로그램 정보 등은 보조기억장치에 저장되어 있음.

RAM -> 주기억장치가 있는데 RAM은 또 왜 필요한 걸까? 그냥 주기억장치에 넣고 처리하면 안되나?

보조기억장치는 CPU에 비해서 데이터 처리 속도가 현저히 느림. 즉 CPU가 아무리 빨라도 보조기억장치의 속도에 맞춰서 느리게 데이터가 처리되는 문제가 생김.

이 문제를 해결하기 위해서 RAM이라는 하드웨어가 도입된 것. 메모리는 CPU의 작업 공간이라고 이해할 수 있음.

CPU가 보조기억장치에 데이터를 요청하면 보조기억장치는 주기억장치에 데이터를 전달하고, CPU는 보조기억장치와 함께 일할 필요 없이 주기억장치에 일하면 됨

한 번에 여러개의 프로그램을 돌리거나 하면 CPU와 메모리가 감당할 수 없는 순간이 발생함.
-> 이 때 컴퓨터는 멈춰버리거나 응답없음이라는 문제가 뜨면서 무한로딩이 걸리거나 한다.

서버도 그냥 컴퓨터임. 그냥 분산 처리를 위해서 좀 몰려있다 뿐이지 사실상 컴퓨터인건 똑같다.

이용자인 클라이언트 컴퓨터가 데이터를 서버에 요청하면, 서버 컴퓨터는 해당 작업을 수행한다.

이 때 한 번에 많은 요청이 오면 어느이상은 감당하지 못해서 우리 노트북이 멈추는것과 비슷하게 서버 컴퓨터도 다운 됨. (이걸 서버가 터졌다라고 표현함.)

다음과 같은 상황들을 포함할 수 있음.

- 서버 무응답: 서버가 요청에 응답하지 않는 상태
- 서버 다운: 서버 프로세스나 서버 컴퓨터 자체가 완전히 중단된 상태
- 과부하: 너무 많은 요청을 처리하느라 서버가 매우 느리게 응답하거나 응답하지 못하는 상태

# 트래픽이 몰린다고 할 때, '트래픽'이 뭐임..?

아니 뭐 이렇게 모르는것 투성이야..ㅋㅋㅋㅋㅋ 아오!!!
