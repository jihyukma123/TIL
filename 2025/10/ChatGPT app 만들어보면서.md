# Apps in ChatGPT에 적용할 수 있는 'App' 만들어보면서 느낀 점

- Railway -> 이런 식으로 간단하게 배포해서 빠르게 Iterate해볼 수 있는 서비스 도움이 많이 됨(ngrok이 되면 좋았는데 왜 안되는거임. 집가서도 해보고 안되면 회사 네트워크 이슈는 아닌걸로....)

# Many Apps SDK projects wrap window.openai access in small hooks so views remain testable.

Apps SDK는 mcp서버에 연결된 UI를 Iframe에 렌더링할 때 host와 연결을 위해서 iframe의 window 객체에 `openai`라는 이름의 커스텀 객체를 추가해서 사전에 정의된 값/메서드를 추가함.

이거는 정해져있는거라서, Apps SDK를 이용한 프로젝트들이 이 `windows.openai` 객체에 접근하는 로직을 custom hook으로 추상화한다고 함.

근데 이해가 안됐던건, 이거랑, `so views remain testable` 이라는 부분이 이해가 잘 안됐음.

Gemini한테 물어봤다. (내가 추측한건, View 로직인 컴포넌트에서 글로벌 객체에 접근하는 로직이 섞여있으면 View 자체의 렌더링 로직을 테스트하기 어렵다는건가?라고 추측함)

근데 내 생각은 되게 일부만 이해한 생각이었음. (UI렌더링만 테스트 하는것의 범위를 넘어선 의미가 있다고 함.)

핵심은 `관심사 분리`와 `의존성 주입`

테스트할 때, hook을 활용해서 전역객체에 접근하고 가져다가 사용하는 로직을 분리하면, 그 hook만 mock 하면 테스트하기가 쉬워진다고 함.

view는 view대로, logic은 logic대로 분리해서 관리하고 테스트한다가 핵심인 것 같음.

결론적으로, Hooks은 실제 호스트 환경(iframe 밖)과의 의존성을 View 컴포넌트로부터 제거하여, 컴포넌트를 순수 함수에 가까운 형태로 만들어 쉽고 안정적으로 단위 테스트할 수 있게 해줍니다.

(순수함수 -> easy to test라는 의미를 다시 한 번 생각해볼만한듯?)

--- 추가로 gemini가 지적해준 내용

테스트 용이성에 대해 한 가지 더 현실적인 부분을 첨언하자면, 대부분의 React 테스트 환경(예: Jest)은 Node.js에서 실행되며, 진짜 브라우저 환경(window, document 객체, Event Loop)을 완벽히 갖추지 못합니다.

window.openai와 같은 커스텀 전역 객체는 테스트 환경에 기본적으로 존재하지 않습니다.

만약 컴포넌트가 Hook 없이 직접 const theme = window.openai.theme;와 같이 접근한다면, Jest 환경에서 실행되는 순간 **window.openai가 undefined이므로 에러(Reference Error)**가 발생하여 테스트 자체가 실패합니다.

Custom Hook을 사용하면, 컴포넌트가 전역 객체 참조를 Hooks 내부로 위임하게 되므로, 테스트 시에는 Hooks을 Mock함으로써 컴포넌트의 에러 발생을 원천적으로 차단하고 원하는 데이터를 주입할 수 있습니다. 이는 안정적이고 격리된 단위 테스트를 가능하게 하는 핵심적인 기술적 방법론입니다.

아하!! 그치 window환경이 test할 때는 뭔지 알 수가 없다. -> 이게 undefined일 때 테스트하기 복잡하게 시나리오를 짜면 테스트가 어렵다. 후후 재밌네.

# 멱등성? idempotent?

이게 뭐더라....

[Idempotent Methods](https://www.rfc-editor.org/rfc/rfc7231#section-4.2.2)

이해한걸 써보자면,

멱등하다는 것은 동일한 작업을 여러번 수행해도 결과를 변경시키지 않는 속성이라고 함.

HTTP 메서드 관점에서는, 그 메서드로 동일한 요청을 여러 번 보내더라도 서버에 미치는 의도된 효과가 한 번만 보낸 경우와 동일할 때 메서드가 멱등한거임.

GET/PUT/DELETE는 항상 멱등하고
POST/PATCH는 멱등하지 않거나 멱등하지 않을 가능성이 있음.

GET/PUT/DELETE는 모종의 이유로(서버 연결이 불안정하거나, 실수로 동일한 request를 2번 보내는 로직이 실행되거나 등등..) 여러 번 실행되어도 결과가 동일함.

그런데 POST/PATCH는 여러 번 수행했을 때 결과가 달라질 가능성이 있음.

POST 생각해보면 유저가 여러 번 생성되어버릴 수 있음. 여러 번 보냈을 때 한 번 보냈을 때 기대되는 효과와 결과가 다름. 멱등하지 않다는 것....

이게 문제가 되는건, POST를 단 한번만 제대로 처리하는게 크리티컬한 서비스들임.

대표적인게 결제인데, 결제 요청을 보냈을 때, 실수로 동일한 요청이 서버에 2번 들어가도 실제로 결제처리는 한 번만 되어야 함. `멱등성이 보장`되어야 한다.

이걸 보장하는 방법은 사실상 하나밖에 없는데, 어떤 방식으로건 해당 요청을 유일하게 식별할 수 있는 메커니즘을 만드는 것.

그래서 이 문제를 해결하는 사실상의 표준의 방법은 멱등성 키를 활용하는 방법이라고 함.

요청에 대해서 식별자를 같이 전송하는 건데, https://datatracker.ietf.org/doc/draft-ietf-httpapi-idempotency-key-header/ 를 참고하면 헤더에 포함시키는 것을 권장한다고 함.

```h
// 아래와 같이 Idempotency-Key를 만들어서 첨부
POST /payments
Idempotency-Key: 550e8400-e29b-41d4-a716-446655440000
Content-Type: application/json

{
  "amount": 10000,
  "currency": "KRW",
  "recipient": "user123"
}

```

다만, key 하나만 가지고는 아주 낮은 확률이라고 해도 중복되는 경우가 있을 수 있음. 그렇기 때문에 key만 가지고 판별하면 안되고, 여러가지를 조합해서 판별하는 것이 필요하다고 함(key + api path + method + userid 등등..)

이거를 그러면 서버에서는 어떻게 중복처리를 방지하는지?

Idempotency-Key와 요청에 대해서 반환된 응답을 저장하는거임.

그래서 요청이 들어왔을 때 DB를 확인해서 이미 있는 key에 대한 요청이면 새롭게 처리하지 않고 바로 저장되어 있는 데이터를 반환해주는 것(이미 반환되었었던 response를 다시 반환) -> 동일한 요청(동일한 식별자를 가지는 요청)에 대해서 동일한 효과가 발생하고 동일한 결과가 반환됨.

근데 load balancer를 사용하고 있으면..? 여러 서버간 어떻게 공유함?

서버 재시작하면..?

그래서 일단 일반 요청이랑 다르게 처리해야된다고 하는듯? 일반 SSOT DB를 한 번 거쳐야한다..
