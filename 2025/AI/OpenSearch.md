# OpenSearch 관련..

hybrid search가 뭔지, semantic, syntactic search가 뭔지 잘 모름..

## Lexical Search vs Semantic Search

### Lexical Search 기반 문서집합에 대한 검색 수행되는 방식

내가 궁금했던 건, 검색 쿼리를 입력했을 때, data set에서 어떤 문서를 결과로 보여줄지가 어떻게 결정되는지임.

lexical search는 `단어 자체의 형태적 일치`가 기본 검색 원리임.

검색어에 포함된 단어가 포함되어 있는 문서를 찾아내는 메커니즘인데, how does this work?

검색 쿼리의 단어나 구문이 문서 내 텍스트와 문자 단위로 일치하는지 확인
-> 의미를 기준으로 판단하는 것이 아니라, 단어가 생겨먹은 형태를 기준으로 매칭 여부를 판단함.

그러면 이렇게 매칭을 시켜서 검색을 수행하기 위해서, 문서와 질의를 각각 어떻게 처리할까?

이거 문득 예전에 json 몰랐을 때랑 비슷한 결이지 않나 하는 생각이 드는데...

- 아이폰앱과 애플워치 앱 간 서로 소통하는 매개체가 뭔지 몰라서 고민했었지....주고받는 데이터는 json 형식이었음.

왜 비슷하다고 생각하냐면, 2가지 서로 달라보이는 사항들을 같이 사용하는 과정에서 어떻게 연결점을 찾을 것인지에 대한 문제라고 생각함.

2가지 요소 - 검색 쿼리와 문서
필요한 것: 검색 쿼리와 문서의 매칭 여부를 판단

그러면 검색 쿼리하고 문서를 어떻게 비교할 수 있는지에 대한 문제 해결이 필요하다는 것을 알 수 있음.

문서를 전처리하는 방법은 다음과 같음

토큰화를 통해서 문서를 단어(토큰) 단위로 분리하고, 정규화를 통해서 소문자로 변환하거나 불필요한 기호를 제거하는 등의 처리를 한다.

이렇게 만들어진 토큰들을 index에 저장하는 것.

예:

> 문서: “Lexical search finds exact word matches.”
> 인덱스: {lexical, search, finds, exact, word, matches}

그러면 검색어를 가지고 문서에서 매칭되는 부분을 찾으려면, 검색어도 동일하게 처리해야겠지??

쿼리도 동일한 방식으로 전처리가 된다고 함.(비교하기 전에, 비교를 위해서 텍스트를 동일한 로직으로 변환한 데이터 set으로 만드는 과정이 필요)

예:

> 쿼리: “word match” → 토큰화 후 {word, match}

이렇게 쿼리를 전처리하면,

검색 시스템에서 이제 쿼리의 각 토큰이 포함된 문서를 인덱스에서 검색함.

- 쿼리 토큰이 등장하는 문서를 찾고
- TF-IDF, BM25 같은 **통계적 점수 계산 방식**으로 **관련성(relevance)** 을 평가합니다.
- 점수가 높은 순서로 문서를 반환합니다.

즉, lexical search는 **“쿼리 단어가 등장하는 문서와 그 빈도/위치 정보를 기반으로 검색”**

# opensearch basics

json 기반으로 동작함.

REST를 활용해서 사용자의 질문과 답변 왔다갔다를 처리

opensearch는 Lucene을 기반으로 문서 검색을 수행함 (아파치 루신은 엔진임. 인덱싱과 검색을 수행하는 핵심 로직)

## 검색 시 동작 흐름

텍스트 기준으로 검색하면 어떻게 되냐면,

Query text: `How does albedo diffuse radiation?`(반사도가 빛의 확산에 어떻게 영향을 주는가?)

Analysis: (분석기가 쿼리문을 토큰화/정규화 등 작업을 통해서 처리함. 소문자 변환, 공백 제거, 텍스트에서 중요한 어간 추출 등 작업 처리)

- how do
- albedo
- diffus
- radiat

이런 분석기에도 종류가 다양하다고 함.

- 표준분석기: 불필요한 공백/기호 제거, 소문자 변환 등 형식적인 작업 처리
- 영어분석기(언어별 분석기): 언어 특성을 고려해서 텍스트를 토큰화
  - the albedo of an object is the extent to which.... -> albedo object extent which diffus...
  - 기계 입장에서 분석기 변환 결과가 더 처리하기 용이한 유형이 됨.

그러면 검색을 하면...

예를 들어서 'albedo', 'radiat' 2개의 토큰이 더 많이 나오는 문서가 있을거고, 상대적으로 적게 나오는 문서가 있을거임.

그러면 2개의 토큰이 더 빈출하는 문서가 무조건 '좋다'라고 할 수 있는가?
-> 그렇지 않은 경우도 많이 존재함.

그래서 단순히 출현빈도만 가지고 유효한 문서를 선택하기에는 반례가 많음.

이를 위해서 걸린 문서들에 대해서, Okapi BM25를 사용해서 scoring을 수행함.

- 확률 검색 모델 기반
- 용어 출현 빈도, 문서 길이, 단어의 희소성 고려
- 짧은 문서에서 일치 시 높은 점수, 긴 문서에서 일치 시 패널티 부여

근데 텍스트 기반 검색(vs 벡터 기반 검색 의 context로 보면 되는 것 같음.)은 장단점이 명확

- BM25 정확도가 높음
- 완전 일치의 경우 적합성 높음

but

- 질의어에 특정 용어가 없거나, 검색어 뒤에 실제 질문의 숨은 의미가 존재하는 경우 이를 파악하는건 한계가 명확함

이렇게 용어가 없거나, 숨은 의도가 없는 경우에 벡터를 활용해볼 수 있음.

## 벡터 엔진 핵심 개념

벡터: 값들의 배열 (입력하는 텍스트/이미지 등이 특정한 숫자들의 배열인 벡터로 치환됨 )
모델: 입력에 대해서 출력을 뱉어내는 함수(미세조정을 통해서 특정 weight와 bias를 가지는 노드들로 구성되어 있음.)
임베딩: 텍스트를 벡터로 변환
LLM: 마찬가지로 함수인데, 엄청나게 큰 데이터를 학습했음.
엔진/알고리즘: 벡터를 저장하고, 유사성을 확인하기 위해서 사용

가장 관련성이 높은 문서를 찾기 위해서 일반적으로 사용되는 알고리즘: K-NN

근데 KNN의 경우 데이터가 많아져서 복잡도가 올라가면 시간이 너무 오래 소요된다는 단점이 있음.

이런 단점을 보완하기 위해서 근사치를 사용하는 ANN(approximate KNN)을 많이 사용한다고 함

ANN 알고리즘 중 하나가 바로 `HNSW(Hierarchical navigable small world)`

동작하는 원리를 간단하게 보면,

HNSW는 여러 레벨의 계층이 존재함. 입력 포인트가 존재하는 레이어에서 시작해서, 모든 레이어마다 다음 작업을 반복해서 가장 근사값을 찾아가는 방식임

- 해당 레이어에서 사용자 질문에 가장 근접한 위치로 이동 후,
- 다음 레이어로 이동해서 다시 사용자 질문에 가장 근접한 위치로 이동...이걸 반복.

이런 반복 과정을 통해서 사용자 질문과 가장 가까운 벡터값으로 이동해서 처리한다.

또 많이 사용되는 알고리즘은 `Inverted file(IVF)`

IVF는 군집화(클러스터링)기반 알고리즘임.

공간 안에서 여러 클러스터 중 적합한 클러스터를 찾아서, 그 안에서 로컬 검색을 수행함.

## OpenSearch에서 Hybrid Search

hybrid search는 lexical search + semantic search를 둘 다 사용하는 거임.

amazon opensearch의 구조는,

Query Phase/Score Normalization and Combination/Fetch Phase로 구성됨

뭐가됐든 중요한건,

Query에 대해서 각각 BM25등을 활용한 Lexical Search랑, KNN등을 활용한 Semantic Search를 둘 다 수행해서, 점수 분포를 동일하게 맞춰서 가중치에 따라 각 검색 점수를 합쳐서, 높은 점수를 가지는 문서 상위 n개를 반환함.

동작 원리가 이렇게 된다.

그러면... 여기서 지금 내가 영향을 줄 수 잇는 값이 뭔지 체크해서 각 값이 어떤 영향을 주는지, 어떤 값들 줬을 때 어떤 변화가 생기는지 파악하면 될 것 같음.

---

참고자료

- https://aws.amazon.com/ko/blogs/big-data/hybrid-search-with-amazon-opensearch-service/
