# Synchronous I/O

요청 전송된 다음에 응답이 올 때까지 blocking 되는 문제가 있었음.

근데 새롭게 알게 된 점은, `sync`라는 용어가 내가 이해하고 있는거랑 달랐음.

나는 `synchronous`하게 실행된다, 즉 순서대로 실행된다의 관점에서만 생각을 했고 지금도 그렇게 이해하고 듣고 있었음.

물론 blocking한다는 것은 코드가 순서대로 실행된다는 것. 하지만 너무 클라이언트 관점에서의 사고방식이었던 것 같다.

sync라는 것은 동기화, 즉 caller와 receiver의 요청-응답 흐름이 동기화된다는 것.

오 동기 비동기 이런거구나. 그치..

동기화! 비동기적 즉 서로 요청-응답 흐름이 동기화되지 않아!

# 비동기 I/O

호출자가 blocking을 피하기 위해서 main thread가 별도의 thread를 열어서 작업을 위임하는 경우도 있음.

그 스레드가 I/O를 처리하고, 메인스레드는 계속 작업을 처리.

- 그 작업을 위해서 새롭게 생성한 스레드는 blocked됨. 하지만? 프로그램 실행 자체는 계속될 수 있음.
- 작업이 완료되면 다시 메인스레드를 호출해서 결과 전달 등등..

약간 좀 꼼수 느낌으로 설명해주긴함.(ㅋㅋㅋ)

무엇보다 caller와 receiver가 동기화되어 있지 않다는 점.

# Sync vs Async in Request-Response

하지만 내가 이해하고 있던 느낌과 비슷하게, 동기적이라는 것은 client와 연관성이 강한 개념

왜? 시간의 차이를 control하지 못하는 주체가 caller니까. caller는 외부 시스템에 `부탁해~~`하고 응답이 언제올지에 대한 예측도 할 수 없고 컨트롤도 할 수 없음.

그렇기 때문에 대부분의 클라이언트 라이브러리들은 비동기 기반 메커니즘을 가지고 있음.

클라이언트는 HTTP 요청 보내고 지할일 계속 하고, 미래의 언젠가 response를 받아서 처리한다.

# asynchronous workload is everywhere

- asynchronous programming(promise/future 등등..)
- asynchronous backend processing
  - client에서 요청한 작업이 be입장에서 오래걸리는 작업이라고 생각해보자. client는 요청을 보내고 다른거 하면서 응답이 오면 처리한다는 측면에서 비동기라고 할 수 있지만, 시스템 전체를 놓고보면 사실상 비동기가 아니라고 볼 수도 있음. 왜? 백엔드는 계속 누군가가 요청에 대한 응답을 기다리고 있다는 걸 알고 있는 상태에서 처리를 해줘야하니까.
  - 그러면 백엔드 입장에서는 뭔가 해야될 일이 닥쳐있는 동기처리가 필요한 상황인데, 오래걸리는 작업이라고 생각하면 이게 좀 안좋지 아무래도....
  - 그러면 어떻게 해결하냐? 일단 FE에 응답을 바로 해. 근데 그러면 작업이 처리가 안됐는데? 큐에 작업을 넣고, 너 작업 일단 대기줄에 넣었거든?? 대기번호 받아가~~(행마 생각도 나네 ㅋㅋㅋㅋ) 그리고 FE는 어떤 방식으로건 해당 작업번호를 통해서 작업 완료된 시점에 다시 받아서 처리할 수 있도록
    - 최근에 AWS Transcribe를 사용해서 진행했던 STT가 딱 이런 느낌인듯?? 오래걸리는 작업임. -> Transcription job을 식별할 수 있는 정보를 받음 -> 나같은 경우는 5초마다 polling하는 형식으로 구현하긴 함.
- asynchronous commits in postgres
  - 변경사항(transaction)을 반영하는 작업이 성공적으로 끝나기 전에 client에 success를 반환 그리고 그 후에 처리... -> 아니 근데 이거 위험하지 않아?? 실패하면 어캄?? (그거에 대해서는 정확하게 설명은 안해주네...흠...)
  - 항상 그렇듯이 얻는것과 잃는 것 사이에서 저울질이 필요
    - 중요한 정보이거나, transaction이다? -> 애초에 비동기 커밋을 안해야겠지.
    - 비동기 커밋을 하면 얻는게 뭐야? 속도임. 속도와 효율. 데이터 손실 위험을 감수하고 성능을 선택하는 케이스.
      - 그러면 잃는 것에 대해서는 `아 이건 어쩔 수 없지 기브앤테이크야`라고 하고 넘어갈게 아니라, 적어도 어떻게 선택에 따른 단점을 hedging 할지에 대해서도 같이 생각해보자.
- asynchronous IO in Linux(epoll, io_uring)
- asynchronous replication
  - replication이 뭐야..? DB관련 얘기였음. 가용성, 읽기 성능 향상, 지리적 분산 등 이점을 얻기 위해서 DB의 데이터를 여러 서버에 복사해서 동기화하는 것
    - Primary DB(Master)와 Replica DB(Slave)가 존재함. Primary DB에 변경사항이 발생하면 Replica DB에도 반영이 되어야 하는데, 이 작업을 동기적으로 하느냐 비동기적으로 하느냐의 차이가 존재함.
      - (대부분 그런지는 경험적으로 알아야겠지만..)강사는 이렇게 설명함. 동기적으로 반영하는 구조에서는 보통 primary db가 바로 변경사항을 반영하는게 아니라, 먼저 복제본들에게 해당 변경사항을 반영하라고 명령함. 그리고 모든 복제본에 처리가된 후에야 primary에 반영한다.(왜이렇게 하지? 반대로 하면 고치는게 더 일이라서 그런가? 근데 메인은 무조건 처리하고 복제본들에서 발생하는 이슈는 복제본 단위로 처리하는게 낫지 않나 모르겠네) 근데 그러면 일관성이 확보되는 대신 시간이 오래걸림.
      - 비동기적으로 처리하면?? consistency를 희생해서 비동기적으로 처리해서 성능을 개선.
        - 니네끼리 싱크는 남는 시간에 알아서 하고 나는 알아서 메인 db에 반영한거 결과 빨리 주셈~~
- asynchronous OS fsync(fs cache)
  - OS에 file을 write한다는 것의 의미가 뭐지?? 아 file을 열어서 해당 파일에 뭔가 내용을 작성한다는 소리임.
  - 파일에 내용을 작성하면? 바로 disk로 갈것같지만 실제로는 아님...일단 먼저 OS File system cache에 저장됨.(Page단위로..) 그리고 비동기적으로 메모리에 일정량의 write가 쌓이면 한 번에 disk에 던지는 형식. (flush라고 표현하는데 이 사람이 그렇게 표현하는 줄 알았는데 claude도 그렇게 표현하는거 보니까 뭔가 관련된 개념이 있나보다..) -> 왜 이렇게 해? 바로바로 저장하면 되잖아? 물론 그럴수도 있겠지만 그러면 비효율이 발생할 가능성이 많음 예를 들어 1바이트 수정하고 저장, 수정하고 저장할 때마다 disk write를 수행하면 아주 작은 단위의 변경사항을 반영하기 위해서 최소 write를 하기 위해서 요구되는 리소스는 사용해야함.(SSD 관점에서 보면, 동일한 위치에 write를 많이 수행하면 죽는다고 함 해당 부분이. 이건 또 신기하네)
    - 참고로 flush는 buffer에 있는 데이터를 다음 단계로 밀어내는 것을 말한다고 함.(말그대로 비우는거니까 flush)
