# AI-assisted coding 변천사

개발자들은 어떻게 AI를 사용해왔고, 사용하고 있으며, 사용하게 될까.

지금 개발자들이 개발하는 방식의 현주소에 대해서 궁금해서 찾아보다가 흐름을 이해하는게 도움이 되겠다 싶었음.

그래서 LLM을 이용하는 SDLC를 구축하는 과정에서 거치게 되는 여러 단계에 대해서 조사했다.

이조차도 AI의 deep research 기능을 써서 조사했다..히히

gemini와 perplexity가 각각 어떤 이야기들을 하는지 한 번 살펴보자.(chatgpt는 별 인사이트가 없었음...요즘 약간 삐리하네 전체적으로.)

## gemini

### 초기 단계: chatting 기반 workflow

ChatGPT, Gemini 등 웹기반 채팅 인터페이스를 활용하는 방식

자연어를 설명하거나, 코드 조각을 복사해서 붙여넣고 물어보는 형식으로 문제를 해결함

문제점이 있음 이 방식은

맥락의 단절이 가장 큰 문제점. LLM은 사용자가 작업하고 있는 컨텍스트에 대한 정보가 없음 사용자가 입력하는 단편적인 정보만 가지고 판단해야함.

비기능적 요구사항을 고려할 수도 없으며, AI가 생성한 결과물을 인간이 코드베이스에 붙여넣는 과정에서 human error 발생 가능성도 있음.

### 중기 단계: IDE 내의 페어 프로그래밍

Cursor 같은 친구들과 함께 개발하는 단계임.

로컬 컨텍스트게 접근이 가능하고, 코드 베이스에 반영하는 작업을 LLM을 기반으로 수행하기 때문에

- 맥락 단절 문제가 약간 더 해결되고
- 코드 작성 생산성이 비약적으로 증가함.

이 단계의 특징은

- 인간은 코드를 작성하는 일이 엄청 줄어들고,
- 맥락을 세밀하게 조정하고, 뭘 해야되는지 지시하는 일의 중요성이 커짐.

### 고급 단계: Multi-Autonomous Agent 기반 DLC

전문화된 Agent간 협력으로 SW를 개발하는 단계

인간은 더이상 구현 과정에 직접 관여하지 않고, 비즈니스 목표나, 상위 수준의 지침만을 제시한다.

에이전트들은 단방향 workflow로 동작하는게 아니라, 서로 피드백을 주고 받으며 작업을 완수할 때 까지 반복적으로 수정 작업을 수행한다.

코드 구현 Agent -> review Agent -> fix -> review 다시 이런 식으로 필요한 부분을 loop을 돌면서 자율적으로 판단해서 개선함.

### 검증의 시대

AI가 코드를 생성하는 속도가 엄청 빠르기 때문에, 병목은 '구현'이 아니라 '검증'으로 급격히 이동함.

다 만든 다음에 검증하는게 아니라, 작게작게 지속적으로 검증하는게 중요하다는 의견이 있음.

### 기술적 부채 쌓이는 속도가 증가함

코드를 많이 생산하는 만큼, 부채를 잘 캐치하지 못하면 부채가 쌓이는 속도도 빨라짐.

예를 들어, 전체 맥락을 고려하지 않고 작은 단위의 작업을 처리하면서 전역에서 재사용되어야 하는 로직을 중복 구현해서 효율이 떨어질 수 있음.

이를 방지하기 위해서 시스템의 건강도와 유지보수 용이성을 측정하는 새로운 지표의 도입이 필요함.

- 코드베이스를 검토하는 Agent를 지속적으로 돌리면서 뭔가를 체크하는건 어때?
  - 중복 확인 Agent
  - 구조 개선 Agent

등등.... 이 Agent 를 하루에 한 번씩 codebase 대상으로 돌리면, 지속적으로 코드베이스와 진화하는 Agent가 될 수 있지 않을까??

-> 이전의 보고서, 오늘의 보고서 등등....

이런걸 이미 하고 있나??

### Context Engineering

가장 큰 기술적 도전은 맥락 공학임.

LLM이 한 번에 처리할 수 있는 토큰 수의 양이 제한되어 있고, 그 turn에서 가장 핵심적인 문제를 해결하는데 필요한 정보만 뽑아내서 전달하는게 가장 중요한 과제임.

Anthropic은 이와 관련해서 이런걸 강조한다고 함.

- 압축
- note taking -> 지속적으로 업데이트 되는 장기 기억 저장소 같은 느낌
- 하위 에이전트 아키텍처 -> Sub-Agent. 복잡한 작업을 여러 개의 하위 작업으로 나눠서 각 Agent가 필요한 최소한의 맥락만을 가지도록 설계
  - 맥락 오염 방지

### 자율적 개발 시대의 생존 전략

- 코드를 작성하는 기술보다는, AI가 생성한 코드의 의도를 파악하고 비즈니스 가치와 일치하는지를 검증하는 기술을 연마해야함.
- AI가 유발하는 기술적 부채 등 문제를 엄격한 공학적 원칙과, 자동화된 검증 파이프라인을 구축해야함.
- 개발의 중심축이 '쓰기' -> '읽기 및 판단하기'로 이동 중.
- 경쟁자로 볼 것이 아니라, 더 중요한 문제에 집중할 수 있게 반복적 작업을 lifting해주는 동료로 여길 것.

## perplexity

기억할만한 포인트만 따로 작성함

### 체크포인트의 중요성

LLM에 개발 작업을 많이 위임할 수록, 인간이 어떤 지점을 확인해야되는지가 중요해짐.

SDLC에서 인간이 개입해야 하는 지점에 대한 경험적 이해 및 최적화가 필요함.

# 결론

몇 가지 결론

- Cursor등을 활용하는 건 너무 당연하고, Cursor도 안쓰고 사람은 명령만 입력하는 단계로 넘어가기 위한 다양한 시도들이 지속적으로 이루어지는 시점이라고 판단됨(다만, 아직 그런 시스템들이 Enterprise 급 시스템들의 기능을 구현/개선하는데 사용되고 있지는 않은 듯. 어떻게 하면 잘 구축할 수 있을지 계속 돌려보고 실험하는 단계 정도?)
- 지금 이 트렌드의 핵심 오브 핵심은 결국 '일 잘 시키기'와, '잘 했는지 검증하기' 임.
  - 잘 시키기 기법은 결국 하나로 귀결되는 걸로 이해함. 'LLM에 적절한 프롬프트 입력하는 구조 만들기' 즉 context engineering임.
  - 잘 했는지 검증하기는 다양한 기법들이 조합되어야 하는 듯.
    - LLM 평가자
    - Test Code
    - HITL
    - 등등...

Context, Context, Context,
